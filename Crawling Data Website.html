
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Crawling Berita Online &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Crawling Data Website';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Welcome to your Jupyter Book" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Crawling Berita Online</strong></a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FCrawling Data Website.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Crawling Data Website.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Crawling Berita Online</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#konsep-crawling">Konsep Crawling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teknik-dan-cara-crawling-menggunakan-python">Teknik dan Cara Crawling Menggunakan Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tool-yang-digunakan-library">Tool yang Digunakan (Library)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-crawling">Proses Crawling</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="crawling-berita-online">
<h1><strong>Crawling Berita Online</strong><a class="headerlink" href="#crawling-berita-online" title="Link to this heading">#</a></h1>
<section id="konsep-crawling">
<h2>Konsep Crawling<a class="headerlink" href="#konsep-crawling" title="Link to this heading">#</a></h2>
<p>Crawling data, atau web scraping, adalah proses otomatis untuk mengumpulkan data dari situs web menggunakan program yang disebut web crawler atau scraper. Program ini bekerja dengan mengakses halaman-halaman web, membaca konten HTML, dan mengekstrak informasi yang relevan seperti teks, gambar, atau tautan.</p>
<p>Untuk melakukan ini, crawler mengirimkan permintaan HTTP ke server web dan kemudian menerima konten halaman sebagai respons. Setelah konten halaman diperoleh, teknik parsing digunakan untuk menavigasi struktur HTML dan mengambil data yang diinginkan, seringkali dengan bantuan pustaka seperti BeautifulSoup atau Scrapy. Data yang diambil kemudian disimpan dalam format yang terstruktur, seperti CSV, JSON, atau dalam database, agar mudah dianalisis lebih lanjut. Saat melakukan crawling, penting untuk memperhatikan frekuensi permintaan agar tidak membebani server dan tetap mematuhi aturan yang ada, seperti file robots.txt atau ketentuan layanan situs web. Web scraping digunakan dalam berbagai aplikasi, termasuk pengumpulan data berita, pemantauan harga produk, dan analisis media sosial. Meskipun sangat berguna, kegiatan ini harus dilakukan dengan mematuhi etika dan peraturan hukum yang berlaku.</p>
</section>
<section id="teknik-dan-cara-crawling-menggunakan-python">
<h2>Teknik dan Cara Crawling Menggunakan Python<a class="headerlink" href="#teknik-dan-cara-crawling-menggunakan-python" title="Link to this heading">#</a></h2>
<p>Crawling data menggunakan Python dapat dilakukan dengan berbagai cara, mulai dari menggunakan pustaka sederhana seperti Requests dan BeautifulSoup untuk kebutuhan dasar, hingga framework yang lebih kompleks seperti Scrapy untuk kebutuhan yang lebih lanjut dan skalabilitas yang lebih tinggi. Teknik ini memungkinkan pengumpulan data otomatis dari situs web untuk berbagai tujuan, seperti analisis data, penelitian, dan pemantauan informasi secara real-time.</p>
<p>Berikut merupakan teknik dan cara Crawling menggunakan Python:</p>
<ol class="arabic simple">
<li><p>Menggunakan Requests dan BeautifulSoup
Berikut merupakan langkah menggunakan Request dan BeautifulSoup untuk Crawling:</p></li>
<li><p>Install library yang dibutuhkan, pastikan untuk menginstal library requests dan beautifulsoup4.</p></li>
<li><p>Mnegirim permintaan HTTP dan mendapatkan konten halaman, Gunakan requests untuk mengirim permintaan HTTP ke halaman web yang ingin di-crawl.</p></li>
<li><p>Parsing HTML dengan BeautifulSoup, gunakan BeautifulSoup untuk parsing HTML dan mengekstrak data yang dibutuhkan.</p></li>
<li><p>Menyimpan Data yang Diperoleh setelah mengekstraksi data, simpan dalam format yang diinginkan seperti CSV, JSON, atau database.</p></li>
<li><p>Menggunakan Scrapy</p></li>
</ol>
<p>Scrapy adalah framework crawling dan scraping yang lebih kuat dan canggih, yang memungkinkan scraping data dari beberapa halaman dengan efisiensi tinggi. Scrapy juga menyediakan berbagai fitur seperti manajemen sesi, pemrosesan asinkron, dan dukungan untuk scraping paralel.</p>
<p>Berikut merupakan langkah-langkah menggunakan scrapy:</p>
<ol class="arabic simple">
<li><p>Install scrapy</p></li>
<li><p>Buat proyek scrapy baru</p></li>
<li><p>Membuat spider scrapy</p></li>
<li><p>Menulis logika crawling dalam spider, buka file spider lalu tulis logika untuk merayapi dan mengekstrak data yang diinginkan.</p></li>
<li><p>Jalankan spider</p></li>
</ol>
</section>
<section id="tool-yang-digunakan-library">
<h2>Tool yang Digunakan (Library)<a class="headerlink" href="#tool-yang-digunakan-library" title="Link to this heading">#</a></h2>
<ol class="arabic">
<li><p>Request</p>
<p>Pustaka ini digunakan untuk mengirim permintaan HTTP ke server web dan mendapatkan konten halaman web. Permintaan HTTP dapat menggunakan metode GET (untuk mengambil data) atau POST (untuk mengirim data).</p>
</li>
<li><p>BeautifulSoup
Setelah konten halaman diperoleh menggunakan Requests, BeautifulSoup digunakan untuk parsing HTML dan mengekstrak elemen-elemen yang diinginkan berdasarkan tag HTML, atribut, atau struktur lainnya.</p></li>
<li><p>Pandas</p></li>
</ol>
<p>Pustaka Python open source yang berfungsi untuk mengolah dan menganalisis data, disini pandas akan digunakan untuk mengelola data hasil scraping dalam bentuk tabel (DataFrame) dan memanipulasi data lebih lanjut.</p>
<ol class="arabic simple" start="4">
<li><p>Time</p></li>
</ol>
<p>Untuk mengatur jeda antara permintaan saat melakukan scraping agar tidak terdeteksi sebagai bot oleh server target.</p>
</section>
<section id="proses-crawling">
<h2>Proses Crawling<a class="headerlink" href="#proses-crawling" title="Link to this heading">#</a></h2>
<p>Install pustaka yang dibutuhkan</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>requests
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>beautifulsoup4
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pandas
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)
Requirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)
Requirement already satisfied: numpy&lt;2,&gt;=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)
Requirement already satisfied: tzdata&gt;=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)
</pre></div>
</div>
</div>
</div>
<p><strong>Mengatur URL Dasar</strong></p>
<p>Isi dengan URL dasar yang akan digunakan untuk mengakses halaman kategori “kuliner” di situs web Kompas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># URL dasar untuk kategori &#39;kuliner&#39;</span>
<span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;https://www.kompas.id/kategori/gaya-hidup/kuliner?open_from=Side_Menu&#39;</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Inisiliasi List Untuk Menyimpan Hasil Scrape</strong></p>
<p>Membuat list kosong yang akan diisi dengan data berita yang berhasil di-scrape dari situs web.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Inisialisasi list untuk menyimpan hasil scrape</span>
<span class="n">data_berita</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Menambahkan Headers</strong></p>
<p>Menentukan “User-Agent” agar permintaan terlihat seperti berasal dari browser biasa, untuk menghindari blokir dari situs web yang mendeteksi permintaan otomatis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tambahkan headers</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3&#39;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Scraping</strong></p>
<ol class="arabic simple">
<li><p>Loop pertama yaitu Loop untuk Pagination</p></li>
</ol>
<ul class="simple">
<li><p>Loop ini digunakan untuk mengakses beberapa halaman (dalam hal ini, halaman 1 hingga 10) dari kategori “kuliner” di situs Kompas. Angka 11 di range(1, 11) menunjukkan bahwa loop ini berjalan untuk 10 halaman (1 sampai 10).</p></li>
<li><p>Menggunakan f-string untuk membuat URL lengkap untuk setiap halaman. base_url adalah URL dasar dari kategori “kuliner”, dan page={page} menambahkan nomor halaman yang sedang diakses.</p></li>
<li><p>Mengirim permintaan HTTP GET ke URL yang sudah dihasilkan dengan requests.get(). headers berisi informasi “User-Agent” untuk menyamar sebagai browser.</p></li>
<li><p>Menggunakan BeautifulSoup untuk mem-parsing respons HTML yang diterima dari situs web, agar kita bisa mengekstrak data yang diperlukan.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Tunggu Sebelum Permintaan Berikutnya
Membuat jeda waktu selama 3 detik sebelum mengirim permintaan berikutnya. Ini bertujuan untuk menghindari pengiriman terlalu banyak permintaan dalam waktu singkat yang bisa menyebabkan server menolak permintaan lebih lanjut atau memblokir IP.</p></li>
<li><p>Menggunakan find_all untuk mencari semua elemen <div> dengan kelas CSS tertentu yang mengidentifikasi bahwa elemen tersebut berisi informasi berita. Kelas CSS digunakan untuk menemukan bagian yang relevan dari halaman web.</p></li>
<li><p>Loop Untuk Iterasi</p></li>
</ol>
<p>Loop ini akan melakukan iterasi melalui setiap elemen berita yang ditemukan. Mengambil elemen judul, link berita, kategori, dan tanggal.
5. Mengambil Konten Isi Berita</p>
<ul class="simple">
<li><p>Mengirim permintaan GET untuk mengakses konten berita lengkap menggunakan link_berita.</p></li>
<li><p>Memeriksa apakah respons dari permintaan tersebut berhasil (kode status 200 menunjukkan sukses).</p></li>
<li><p>Mem-parsing respons HTML dari konten berita menggunakan BeautifulSoup.</p></li>
<li><p>Mencari elemen paragraf (<p>) yang berisi isi berita menggunakan kelas CSS tertentu.</p></li>
<li><p>kemudian dibuat kondisi apakah elemen berisi isi berita ditemukan, jika tidak maka diatur ke ‘N/A’</p></li>
<li><p>Menyimpan data berita yang berhasil diambil (judul, isi berita, tanggal, kategori) ke dalam list data_berita. Data ini nantinya akan digunakan untuk membuat DataFrame atau disimpan dalam file CSV.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Loop untuk menangani pagination</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>  <span class="c1"># Misalnya, kita ambil 10 halaman</span>
    <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_url</span><span class="si">}</span><span class="s1">?page=</span><span class="si">{</span><span class="n">page</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

    <span class="c1"># Tunggu 2-5 detik sebelum permintaan berikutnya</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

    <span class="n">berita_items</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;block clearfix text-grey-60 kui-PGc kui-2Qi kui-Ysv&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">berita_items</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">judul</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;h4&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;hover:underline font-sans leading-tight text-grey-60 hover:underline&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get_text</span><span class="p">(</span><span class="n">strip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">link_berita</span> <span class="o">=</span> <span class="s1">&#39;https://www.kompas.id&#39;</span> <span class="o">+</span> <span class="n">item</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">)[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span>
            <span class="n">kategori</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;span&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">get_text</span><span class="p">(</span><span class="n">strip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;span&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;N/A&#39;</span>
            <span class="n">tanggal</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)[</span><span class="s1">&#39;datetime&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;N/A&#39;</span>

            <span class="n">response_berita</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">link_berita</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">response_berita</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
                <span class="n">soup_berita</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response_berita</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
                <span class="n">isi_berita_element</span> <span class="o">=</span> <span class="n">soup_berita</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;ksm-1ST ksm-2Uv&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">isi_berita_element</span><span class="p">:</span>
                    <span class="n">isi_berita</span> <span class="o">=</span> <span class="n">isi_berita_element</span><span class="o">.</span><span class="n">get_text</span><span class="p">(</span><span class="n">strip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">isi_berita</span> <span class="o">=</span> <span class="s1">&#39;N/A&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to fetch article content, status code: </span><span class="si">{</span><span class="n">response_berita</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">isi_berita</span> <span class="o">=</span> <span class="s1">&#39;N/A&#39;</span>

            <span class="n">data_berita</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;Judul&#39;</span><span class="p">:</span> <span class="n">judul</span><span class="p">,</span>
                <span class="s1">&#39;Isi Berita&#39;</span><span class="p">:</span> <span class="n">isi_berita</span><span class="p">,</span>
                <span class="s1">&#39;Tanggal&#39;</span><span class="p">:</span> <span class="n">tanggal</span><span class="p">,</span>
                <span class="s1">&#39;Kategori&#39;</span><span class="p">:</span> <span class="n">kategori</span><span class="p">,</span>
                <span class="c1"># &#39;Link&#39;: link_berita</span>
            <span class="p">})</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Error processing item: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ipython-input-5-279edfa05864&gt;:16: DeprecationWarning: The &#39;text&#39; argument to find()-type methods is deprecated. Use &#39;string&#39; instead.
  kategori = item.find(&#39;span&#39;, text=True).get_text(strip=True) if item.find(&#39;span&#39;, text=True) else &#39;N/A&#39;
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-5-279edfa05864&gt;</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span>             <span class="n">tanggal</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)[</span><span class="s1">&#39;datetime&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;N/A&#39;</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span> 
<span class="ne">---&gt; </span><span class="mi">19</span>             <span class="n">response_berita</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">link_berita</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span> 
<span class="g g-Whitespace">     </span><span class="mi">21</span>             <span class="k">if</span> <span class="n">response_berita</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/requests/api.py</span> in <span class="ni">get</span><span class="nt">(url, params, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">71</span>     <span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">72</span><span class="s2"> </span>
<span class="ne">---&gt; </span><span class="mi">73</span><span class="s2">     return request(&quot;get&quot;, url, params=params, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">74</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">75</span><span class="s2"> </span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/requests/api.py</span> in <span class="ni">request</span><span class="nt">(method, url, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span><span class="s2">     # cases, and look like a memory leak in others.</span>
<span class="g g-Whitespace">     </span><span class="mi">58</span><span class="s2">     with sessions.Session() as session:</span>
<span class="ne">---&gt; </span><span class="mi">59</span><span class="s2">         return session.request(method=method, url=url, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">61</span><span class="s2"> </span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/requests/sessions.py</span> in <span class="ni">request</span><span class="nt">(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)</span>
<span class="g g-Whitespace">    </span><span class="mi">587</span><span class="s2">         }</span>
<span class="g g-Whitespace">    </span><span class="mi">588</span><span class="s2">         send_kwargs.update(settings)</span>
<span class="ne">--&gt; </span><span class="mi">589</span><span class="s2">         resp = self.send(prep, **send_kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">590</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">591</span><span class="s2">         return resp</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/requests/sessions.py</span> in <span class="ni">send</span><span class="nt">(self, request, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">701</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">702</span><span class="s2">         # Send the request</span>
<span class="ne">--&gt; </span><span class="mi">703</span><span class="s2">         r = adapter.send(request, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">704</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">705</span><span class="s2">         # Total elapsed time of the request (approximately)</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/requests/adapters.py</span> in <span class="ni">send</span><span class="nt">(self, request, stream, timeout, verify, cert, proxies)</span>
<span class="g g-Whitespace">    </span><span class="mi">665</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">666</span><span class="s2">         try:</span>
<span class="ne">--&gt; </span><span class="mi">667</span><span class="s2">             resp = conn.urlopen(</span>
<span class="g g-Whitespace">    </span><span class="mi">668</span><span class="s2">                 method=request.method,</span>
<span class="g g-Whitespace">    </span><span class="mi">669</span><span class="s2">                 url=url,</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py</span> in <span class="ni">urlopen</span><span class="nt">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">789</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">790</span><span class="s2">             # Make the request on the HTTPConnection object</span>
<span class="ne">--&gt; </span><span class="mi">791</span><span class="s2">             response = self._make_request(</span>
<span class="g g-Whitespace">    </span><span class="mi">792</span><span class="s2">                 conn,</span>
<span class="g g-Whitespace">    </span><span class="mi">793</span><span class="s2">                 method,</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py</span> in <span class="ni">_make_request</span><span class="nt">(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)</span>
<span class="g g-Whitespace">    </span><span class="mi">535</span><span class="s2">         # Receive the response from the server</span>
<span class="g g-Whitespace">    </span><span class="mi">536</span><span class="s2">         try:</span>
<span class="ne">--&gt; </span><span class="mi">537</span><span class="s2">             response = conn.getresponse()</span>
<span class="g g-Whitespace">    </span><span class="mi">538</span><span class="s2">         except (BaseSSLError, OSError) as e:</span>
<span class="g g-Whitespace">    </span><span class="mi">539</span><span class="s2">             self._raise_timeout(err=e, url=url, timeout_value=read_timeout)</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/urllib3/connection.py</span> in <span class="ni">getresponse</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">459</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">460</span><span class="s2">         # Get the response from http.client.HTTPConnection</span>
<span class="ne">--&gt; </span><span class="mi">461</span><span class="s2">         httplib_response = super().getresponse()</span>
<span class="g g-Whitespace">    </span><span class="mi">462</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">463</span><span class="s2">         try:</span>

<span class="nn">/usr/lib/python3.10/http/client.py</span> in <span class="ni">getresponse</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1373</span><span class="s2">         try:</span>
<span class="g g-Whitespace">   </span><span class="mi">1374</span><span class="s2">             try:</span>
<span class="ne">-&gt; </span><span class="mi">1375</span><span class="s2">                 response.begin()</span>
<span class="g g-Whitespace">   </span><span class="mi">1376</span><span class="s2">             except ConnectionError:</span>
<span class="g g-Whitespace">   </span><span class="mi">1377</span><span class="s2">                 self.close()</span>

<span class="nn">/usr/lib/python3.10/http/client.py</span> in <span class="ni">begin</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">316</span><span class="s2">         # read until we get a non-100 response</span>
<span class="g g-Whitespace">    </span><span class="mi">317</span><span class="s2">         while True:</span>
<span class="ne">--&gt; </span><span class="mi">318</span><span class="s2">             version, status, reason = self._read_status()</span>
<span class="g g-Whitespace">    </span><span class="mi">319</span><span class="s2">             if status != CONTINUE:</span>
<span class="g g-Whitespace">    </span><span class="mi">320</span><span class="s2">                 break</span>

<span class="nn">/usr/lib/python3.10/http/client.py</span> in <span class="ni">_read_status</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">277</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">278</span><span class="s2">     def _read_status(self):</span>
<span class="ne">--&gt; </span><span class="mi">279</span><span class="s2">         line = str(self.fp.readline(_MAXLINE + 1), &quot;iso-8859-1&quot;)</span>
<span class="g g-Whitespace">    </span><span class="mi">280</span><span class="s2">         if len(line) &gt; _MAXLINE:</span>
<span class="g g-Whitespace">    </span><span class="mi">281</span><span class="s2">             raise LineTooLong(&quot;status line&quot;)</span>

<span class="nn">/usr/lib/python3.10/socket.py</span> in <span class="ni">readinto</span><span class="nt">(self, b)</span>
<span class="g g-Whitespace">    </span><span class="mi">703</span><span class="s2">         while True:</span>
<span class="g g-Whitespace">    </span><span class="mi">704</span><span class="s2">             try:</span>
<span class="ne">--&gt; </span><span class="mi">705</span><span class="s2">                 return self._sock.recv_into(b)</span>
<span class="g g-Whitespace">    </span><span class="mi">706</span><span class="s2">             except timeout:</span>
<span class="g g-Whitespace">    </span><span class="mi">707</span><span class="s2">                 self._timeout_occurred = True</span>

<span class="nn">/usr/lib/python3.10/ssl.py</span> in <span class="ni">recv_into</span><span class="nt">(self, buffer, nbytes, flags)</span>
<span class="g g-Whitespace">   </span><span class="mi">1301</span><span class="s2">                   &quot;non-zero flags not allowed in calls to recv_into() on </span><span class="si">%s</span><span class="s2">&quot; %</span>
<span class="g g-Whitespace">   </span><span class="mi">1302</span><span class="s2">                   self.__class__)</span>
<span class="ne">-&gt; </span><span class="mi">1303</span><span class="s2">             return self.read(nbytes, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1304</span><span class="s2">         else:</span>
<span class="g g-Whitespace">   </span><span class="mi">1305</span><span class="s2">             return super().recv_into(buffer, nbytes, flags)</span>

<span class="nn">/usr/lib/python3.10/ssl.py</span> in <span class="ni">read</span><span class="nt">(self, len, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1157</span><span class="s2">         try:</span>
<span class="g g-Whitespace">   </span><span class="mi">1158</span><span class="s2">             if buffer is not None:</span>
<span class="ne">-&gt; </span><span class="mi">1159</span><span class="s2">                 return self._sslobj.read(len, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1160</span><span class="s2">             else:</span>
<span class="g g-Whitespace">   </span><span class="mi">1161</span><span class="s2">                 return self._sslobj.read(len)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<p>Print data berita dengan dataframe</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_berita</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                Judul  \
0                Nyanyian Kelezatan Kuliner Nusantara   
1                                      Kue Basah Asin   
2   Icip-icip Soto Betawi dan Mi Ayam di Sekitar S...   
3           Musim Semi Kuliner di Sekitar Stasiun MRT   
4        Berburu Kuliner Viral di Sekitar Stasiun MRT   
..                                                ...   
95                           Inspirasi Menu Sederhana   
96                    Gurih Legit Bebek Madura Ma’Isa   
97      Merayakan Kebinekaan Menu Zamrud Khatulistiwa   
98              Cita Rasa Malaysia di Selatan Jakarta   
99                 Australia Gencarkan Promosi Pangan   

                                           Isi Berita              Tanggal  \
0   Merayakan hari baik dengan makan-makan bermenu...  2024-08-18 14:05:23   
1   Selama ini kue basah digambarkan sebagai kue y...  2024-08-18 09:00:38   
2   Usahakulinerdi sekitar stasiunMRTsemakin berag...  2024-08-16 14:30:00   
3   Setidaknya satu-dua tahun terakhir, kawasan se...  2024-08-11 08:30:09   
4                                                 N/A  2024-08-11 08:08:09   
..                                                ...                  ...   
95                                                N/A  2024-08-04 09:33:41   
96  Berbekal ingatan akan leluhurnya,Aisa(67) berd...  2024-08-04 07:00:05   
97  Aneka hidangan terbaru disodorkan olehKaum. Ta...  2024-07-25 11:00:55   
98  Saat pertama kali melangkah masuk ke dalam ked...  2024-07-13 20:39:19   
99  Komisi Perdagangan dan Investasi Australia (Au...  2024-06-21 09:05:06   

   Kategori  
0   Kuliner  
1   Kuliner  
2   Kuliner  
3   Kuliner  
4   Kuliner  
..      ...  
95  Kuliner  
96  Kuliner  
97  Kuliner  
98  Kuliner  
99  Kuliner  

[100 rows x 4 columns]
</pre></div>
</div>
</div>
</div>
<p><strong>Menyimpan Data Dalam CSV</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simpan hasil ke CSV jika perlu</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;/content/drive/MyDrive/KULIAH/SEMESTER 7/PPW/TUGAS/data_berita_kuliner.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Welcome to your Jupyter Book</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#konsep-crawling">Konsep Crawling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teknik-dan-cara-crawling-menggunakan-python">Teknik dan Cara Crawling Menggunakan Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tool-yang-digunakan-library">Tool yang Digunakan (Library)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-crawling">Proses Crawling</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>